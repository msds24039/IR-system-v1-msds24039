{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0410e754-0163-4982-a15b-3ced6ac1f955",
   "metadata": {},
   "source": [
    "*Information Retrieval IR system*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ac877a6-4893-40af-9689-34b15a921387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customized function for statistical insights of dataset\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "class CorpusAnalyzer:\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "        self.stats = {\n",
    "            \"hyphens\": Counter(),\n",
    "            \"apostrophes\": Counter(),\n",
    "            \"acronyms\": Counter(),\n",
    "            \"colons\": Counter(),\n",
    "            \"numbers\": Counter()\n",
    "        }\n",
    "\n",
    "    def analyze(self):\n",
    "        print(\"Analyzing corpus for special token patterns...\")\n",
    "        \n",
    "        for doc in self.documents:\n",
    "            text = f\"{doc['heading']} {doc['content']}\"\n",
    "            \n",
    "            # Hyphenated words \n",
    "            hyphens = re.findall(r'\\b[a-zA-Z]+-[a-zA-Z]+\\b', text)\n",
    "            self.stats[\"hyphens\"].update(hyphens)\n",
    "            \n",
    "            # Apostrophes\n",
    "            apostrophes = re.findall(r'\\b[a-zA-Z]+\\'[a-zA-Z]+\\b', text)\n",
    "            self.stats[\"apostrophes\"].update(apostrophes)\n",
    "            \n",
    "            # Acronyms / Abbreviations with dots\n",
    "            acronyms = re.findall(r'\\b(?:[A-Z]\\.)+[A-Z]?\\b', text)\n",
    "            self.stats[\"acronyms\"].update(acronyms)\n",
    "            \n",
    "            # Colons (often used in news for \"KARACHI: ...\")\n",
    "            colons = re.findall(r'\\b[A-Z][a-zA-Z]*:', text)\n",
    "            self.stats[\"colons\"].update(colons)\n",
    "\n",
    "    def print_report(self):\n",
    "        print(\"\\n=== CORPUS ANALYSIS REPORT ===\")\n",
    "        \n",
    "        print(f\"\\n[Hyphenated Words] Top 10 of {len(self.stats['hyphens'])} unique:\")\n",
    "        for w, c in self.stats['hyphens'].most_common(10):\n",
    "            print(f\"  {w}: {c}\")\n",
    "            \n",
    "        print(f\"\\n[Apostrophes] Top 10 of {len(self.stats['apostrophes'])} unique:\")\n",
    "        for w, c in self.stats['apostrophes'].most_common(10):\n",
    "            print(f\"  {w}: {c}\")\n",
    "            \n",
    "        print(f\"\\n[Acronyms] Top 10 of {len(self.stats['acronyms'])} unique:\")\n",
    "        for w, c in self.stats['acronyms'].most_common(10):\n",
    "            print(f\"  {w}: {c}\")\n",
    "            \n",
    "        print(f\"\\n[Colons/Headers] Top 10:\")\n",
    "        for w, c in self.stats['colons'].most_common(10):\n",
    "            print(f\"  {w}: {c}\")\n",
    "\n",
    "        print(\"\\n=== RECOMMENDATION ===\")\n",
    "        self._generate_recommendation()\n",
    "\n",
    "    def _generate_recommendation(self):\n",
    "        # Heuristics for auto-recommendation\n",
    "        hyphen_count = sum(self.stats['hyphens'].values())\n",
    "        acronym_count = sum(self.stats['acronyms'].values())\n",
    "        \n",
    "        print(\"Based on stats:\")\n",
    "        if hyphen_count > 100:\n",
    "            print(\"- Hyphens: HIGH FREQUENCY. Recommendation: Keep hyphenated words intact (e.g., 'supply-side' -> 'supply-side'). Splitting them might lose specific meaning.\")\n",
    "        else:\n",
    "            print(\"- Hyphens: Low frequency. Recommendation: Split freely.\")\n",
    "\n",
    "        if acronym_count > 50:\n",
    "            print(\"- Acronyms: DETECTED. Recommendation: Normalize by removing dots (U.S. -> US) to match user queries like 'US'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b52a5f4-749d-428f-956b-5147d1a4cbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import math\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Download necessary NLTK data (run once)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# CONFIGURATION & LOGGING\n",
    "class IRConfig:\n",
    "    \"\"\"Central configuration for the IR System.\"\"\"\n",
    "    DATA_PATH = r\"C:\\Users\\user\\Documents\\Sem 3\\HW3\\dataset\\Articles.csv\"\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "    STEMMER = PorterStemmer()\n",
    "    \n",
    "    # BM25 Hyperparameters (Standard defaults)\n",
    "    K1 = 1.5\n",
    "    B = 0.75\n",
    "\n",
    "def log(msg):\n",
    "    print(f\"[System Log]: {msg}\")\n",
    "\n",
    "# DATA INGESTION\n",
    "def load_data(filepath):\n",
    "    \"\"\"\n",
    "    Reads the CSV with robust handling for multi-line fields and encoding errors.\n",
    "    \"\"\"\n",
    "    log(f\"Loading dataset from {filepath}...\")\n",
    "    documents = []\n",
    "    \n",
    "    # List of encodings to try. \n",
    "    encodings_to_try = ['utf-8', 'cp1252', 'latin1', 'ISO-8859-1']\n",
    "    \n",
    "    df = None\n",
    "    \n",
    "    for encoding in encodings_to_try:\n",
    "        try:\n",
    "            log(f\"Attempting to load with encoding: {encoding}...\")\n",
    "            df = pd.read_csv(filepath, encoding=encoding)\n",
    "            log(f\"Success with encoding: {encoding}\")\n",
    "            break # Stop if successful\n",
    "        except UnicodeDecodeError:\n",
    "            log(f\"Failed with encoding: {encoding}, trying next...\")\n",
    "        except Exception as e:\n",
    "            log(f\"Unexpected error with {encoding}: {e}\")\n",
    "            break\n",
    "\n",
    "    if df is None:\n",
    "        log(\"Critical Error: Could not read file with any supported encoding.\")\n",
    "        return []\n",
    "\n",
    "    # Process the dataframe\n",
    "    try:\n",
    "        # Handling NaN values by replacing them with empty strings\n",
    "        df = df.fillna('')\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            # Robust cleaning: remove potential non-breaking spaces or weird whitespace\n",
    "            clean_content = str(row['Article']).strip()\n",
    "            clean_heading = str(row['Heading']).strip()\n",
    "            \n",
    "            doc = {\n",
    "                'id': index,\n",
    "                'content': clean_content,\n",
    "                'heading': clean_heading,\n",
    "                'date': str(row['Date']),\n",
    "                'type': str(row['NewsType'])\n",
    "            }\n",
    "            documents.append(doc)\n",
    "            \n",
    "        log(f\"Successfully loaded {len(documents)} documents.\")\n",
    "        return documents\n",
    "        \n",
    "    except Exception as e:\n",
    "        log(f\"Error parsing dataframe content: {e}\")\n",
    "        return []\n",
    "\n",
    "# PREPROCESSING\n",
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    Pipeline: Lowercase -> Remove Special Chars -> Tokenize -> Remove Stopwords -> Stem\n",
    "    \"\"\"\n",
    "    # 1. Lowercase and remove non-alphanumeric (keep spaces)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text.lower())\n",
    "    \n",
    "    # 2. Tokenize (split by whitespace)\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # 3. Stopword removal & Stemming\n",
    "    clean_tokens = [\n",
    "        IRConfig.STEMMER.stem(t) \n",
    "        for t in tokens \n",
    "        if t not in IRConfig.STOPWORDS\n",
    "    ]\n",
    "    \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ab68b41-b119-4a9a-8aad-74810060af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Indexer:\n",
    "    def __init__(self):\n",
    "        self.inverted_index = defaultdict(dict) # term -> {doc_id: freq}\n",
    "        self.doc_lengths = {} # doc_id -> length (needed for BM25)\n",
    "        self.avg_doc_length = 0\n",
    "        self.total_docs = 0\n",
    "        self.corpus_stats = {} # store idf later\n",
    "        \n",
    "    def build_index(self, documents):\n",
    "        \"\"\"\n",
    "        Constructs the inverted index from the document corpus.\n",
    "        \"\"\"\n",
    "        log(\"Building Inverted Index...\")\n",
    "        total_length = 0\n",
    "        \n",
    "        for doc in documents:\n",
    "            doc_id = doc['id']\n",
    "            # We index both Heading and Article Content for better recall\n",
    "            full_text = f\"{doc['heading']} {doc['content']}\"\n",
    "            tokens = preprocess(full_text)\n",
    "            \n",
    "            # 1. Update Document Lengths (for BM25 normalization)\n",
    "            self.doc_lengths[doc_id] = len(tokens)\n",
    "            total_length += len(tokens)\n",
    "            \n",
    "            # 2. Build Inverted Index\n",
    "            term_freqs = Counter(tokens)\n",
    "            for term, freq in term_freqs.items():\n",
    "                self.inverted_index[term][doc_id] = freq\n",
    "                \n",
    "        self.total_docs = len(documents)\n",
    "        self.avg_doc_length = total_length / self.total_docs if self.total_docs > 0 else 0\n",
    "        \n",
    "        log(f\"Indexing complete. Vocabulary size: {len(self.inverted_index)} terms.\")\n",
    "        \n",
    "    def get_postings(self, term):\n",
    "        \"\"\"Returns {doc_id: freq} for a given term.\"\"\"\n",
    "        return self.inverted_index.get(term, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f06570-b097-40b3-ae20-aa4bae250a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalSystem:\n",
    "    def __init__(self, indexer):\n",
    "        self.indexer = indexer\n",
    "        \n",
    "    def _calculate_idf(self, term):\n",
    "        \"\"\"\n",
    "        Calculates Inverse Document Frequency (IDF) for a term.\n",
    "        Using standard log formulation.\n",
    "        \"\"\"\n",
    "        doc_freq = len(self.indexer.get_postings(term))\n",
    "        if doc_freq == 0:\n",
    "            return 0\n",
    "        # Standard IDF formula: log( (N - n + 0.5) / (n + 0.5) + 1 ) \n",
    "        # Adding 1 to avoid negative values\n",
    "        N = self.indexer.total_docs\n",
    "        return math.log(1 + (N - doc_freq + 0.5) / (doc_freq + 0.5))\n",
    "\n",
    "    def boolean_retrieve(self, query):\n",
    "        \"\"\"\n",
    "        Basic AND retrieval. Returns documents containing ALL query terms.\n",
    "        \"\"\"\n",
    "        query_terms = preprocess(query)\n",
    "        if not query_terms:\n",
    "            return []\n",
    "        \n",
    "        # Start with the set of docs for the first term\n",
    "        first_term_docs = set(self.indexer.get_postings(query_terms[0]).keys())\n",
    "        \n",
    "        # Intersect with all other terms\n",
    "        for term in query_terms[1:]:\n",
    "            term_docs = set(self.indexer.get_postings(term).keys())\n",
    "            first_term_docs = first_term_docs.intersection(term_docs)\n",
    "            \n",
    "        return list(first_term_docs)\n",
    "\n",
    "    def bm25_rank(self, query, top_k=5):\n",
    "        \"\"\"\n",
    "        Performs Ranked Retrieval using Okapi BM25.\n",
    "        \"\"\"\n",
    "        query_terms = preprocess(query)\n",
    "        scores = defaultdict(float)\n",
    "        \n",
    "        for term in query_terms:\n",
    "            postings = self.indexer.get_postings(term)\n",
    "            idf = self._calculate_idf(term)\n",
    "            \n",
    "            for doc_id, freq in postings.items():\n",
    "                # BM25 Component Calculation\n",
    "                doc_len = self.indexer.doc_lengths[doc_id]\n",
    "                avg_len = self.indexer.avg_doc_length\n",
    "                k1 = IRConfig.K1\n",
    "                b = IRConfig.B\n",
    "                \n",
    "                numerator = freq * (k1 + 1)\n",
    "                denominator = freq + k1 * (1 - b + b * (doc_len / avg_len))\n",
    "                \n",
    "                # Accumulate score for this doc\n",
    "                scores[doc_id] += idf * (numerator / denominator)\n",
    "                \n",
    "        # Sort by score descending\n",
    "        ranked_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        return ranked_docs[:top_k]\n",
    "\n",
    "    def expand_query_with_feedback(self, original_query, relevant_doc_id, alpha=1.0, beta=0.75):\n",
    "            \"\"\"\n",
    "            Simple Rocchio-like Feedback:\n",
    "            New Query Vector = Alpha * Old Query + Beta * Relevant Doc Vector\n",
    "            \n",
    "            In practice (for text), we append top terms from the relevant doc to the query.\n",
    "            \"\"\"\n",
    "            # Get terms from the relevant document\n",
    "            relevant_doc_terms = []\n",
    "            for term, postings in self.indexer.inverted_index.items():\n",
    "                if relevant_doc_id in postings:\n",
    "                    relevant_doc_terms.append(term)\n",
    "            \n",
    "            # Simple implementation: Add top 3 most frequent terms from the doc \n",
    "            # that aren't already in the query\n",
    "            current_terms = set(preprocess(original_query))\n",
    "            \n",
    "            # Sort doc terms by frequency in that doc\n",
    "            sorted_terms = sorted(relevant_doc_terms, \n",
    "                                  key=lambda t: self.indexer.inverted_index[t][relevant_doc_id], \n",
    "                                  reverse=True)\n",
    "            \n",
    "            added = 0\n",
    "            new_query_parts = [original_query]\n",
    "            \n",
    "            for term in sorted_terms:\n",
    "                if term not in current_terms and added < 3:\n",
    "                    new_query_parts.append(term)\n",
    "                    added += 1\n",
    "                    \n",
    "            return \" \".join(new_query_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5f785fb-91ad-44c3-b66b-37174c53ae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN EXECUTION PIPELINE\n",
    "\n",
    "def main():\n",
    "    # 1. Initialize System\n",
    "    log(\"Initializing CS516 IR System...\")\n",
    "    \n",
    "    # NOTE: You would use the path provided in your prompt:\n",
    "    filepath = r\"C:\\Users\\user\\Documents\\Sem 3\\HW3\\dataset\\Articles.csv\"\n",
    "    \n",
    "    # For demonstration purposes, I will create a dummy CSV file to make this code runnable right now\n",
    "    # In your local jupyter, you can skip this 'create_dummy_csv' step.\n",
    "    # create_dummy_csv(filepath) \n",
    "    \n",
    "    docs = load_data(filepath)\n",
    "    if not docs:\n",
    "        return\n",
    "\n",
    "    # ... after loading docs ...\n",
    "    analyzer = CorpusAnalyzer(docs)\n",
    "    analyzer.analyze()\n",
    "    analyzer.print_report()\n",
    "    \n",
    "    # Pause to let you read the report\n",
    "    input(\"\\nPress Enter to continue to Indexing based on these insights...\")\n",
    "    \n",
    "    # 2. Build Index\n",
    "    indexer = Indexer()\n",
    "    indexer.build_index(docs)\n",
    "    \n",
    "    # 3. Init Retrieval Engine\n",
    "    engine = RetrievalSystem(indexer)\n",
    "    \n",
    "    # 4. Interactive Loop\n",
    "    while True:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        user_query = input(\"Enter Query (or 'exit' to quit): \")\n",
    "        if user_query.lower() == 'exit':\n",
    "            break\n",
    "            \n",
    "        # -- VARIANT A: Boolean Search --\n",
    "        print(f\"\\n[Boolean Retrieval] for '{user_query}':\")\n",
    "        bool_results = engine.boolean_retrieve(user_query)\n",
    "        if bool_results:\n",
    "            for doc_id in bool_results:\n",
    "                print(f\" - Found in Doc ID {doc_id}: {docs[doc_id]['heading'][:50]}...\")\n",
    "        else:\n",
    "            print(\" - No exact matches found (Boolean).\")\n",
    "\n",
    "        # -- VARIANT B: Ranked Retrieval (BM25) --\n",
    "        print(f\"\\n[Ranked Retrieval - BM25] for '{user_query}':\")\n",
    "        ranked_results = engine.bm25_rank(user_query)\n",
    "        \n",
    "        if not ranked_results:\n",
    "            print(\" - No relevant documents found.\")\n",
    "            continue\n",
    "            \n",
    "        for rank, (doc_id, score) in enumerate(ranked_results, 1):\n",
    "            print(f\" {rank}. Doc {doc_id} (Score: {score:.4f}) | {docs[doc_id]['heading']}\")\n",
    "            \n",
    "        # -- VARIANT C: Relevance Feedback Demo --\n",
    "        # Let's assume the user liked the first result and wants \"more like this\"\n",
    "        if ranked_results:\n",
    "            top_doc_id = ranked_results[0][0]\n",
    "            print(f\"\\n[Relevance Feedback] Assuming you liked Doc {top_doc_id}...\")\n",
    "            expanded_query = engine.expand_query_with_feedback(user_query, top_doc_id)\n",
    "            print(f\" - Optimized Query: '{expanded_query}'\")\n",
    "            print(\" - Re-running search with optimized query...\")\n",
    "            \n",
    "            new_results = engine.bm25_rank(expanded_query)\n",
    "            for rank, (doc_id, score) in enumerate(new_results, 1):\n",
    "                print(f\" {rank}. Doc {doc_id} (Score: {score:.4f}) | {docs[doc_id]['heading']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a847faa-47cb-4abd-8859-14b8d8d3c676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[System Log]: Initializing CS516 IR System...\n",
      "[System Log]: Loading dataset from C:\\Users\\user\\Documents\\Sem 3\\HW3\\dataset\\Articles.csv...\n",
      "[System Log]: Attempting to load with encoding: utf-8...\n",
      "[System Log]: Failed with encoding: utf-8, trying next...\n",
      "[System Log]: Attempting to load with encoding: cp1252...\n",
      "[System Log]: Success with encoding: cp1252\n",
      "[System Log]: Successfully loaded 2692 documents.\n",
      "Analyzing corpus for special token patterns...\n",
      "\n",
      "=== CORPUS ANALYSIS REPORT ===\n",
      "\n",
      "[Hyphenated Words] Top 10 of 2855 unique:\n",
      "  year-old: 416\n",
      "  one-day: 170\n",
      "  left-arm: 157\n",
      "  all-rounder: 104\n",
      "  semi-final: 92\n",
      "  Misbah-ul: 91\n",
      "  leg-spinner: 86\n",
      "  semi-finals: 83\n",
      "  Asia-Pacific: 76\n",
      "  five-year: 73\n",
      "\n",
      "[Apostrophes] Top 10 of 784 unique:\n",
      "  world's: 152\n",
      "  It's: 131\n",
      "  Pakistan's: 117\n",
      "  country's: 95\n",
      "  China's: 91\n",
      "  India's: 90\n",
      "  it's: 88\n",
      "  I'm: 79\n",
      "  England's: 73\n",
      "  don't: 70\n",
      "\n",
      "[Acronyms] Top 10 of 28 unique:\n",
      "  U.S: 746\n",
      "  D.: 5\n",
      "  U.K: 5\n",
      "  U.S.: 4\n",
      "  D.G: 2\n",
      "  D.C: 2\n",
      "  U.N: 2\n",
      "  C.: 2\n",
      "  J.P: 2\n",
      "  A.B: 2\n",
      "\n",
      "[Colons/Headers] Top 10:\n",
      "  ISLAMABAD:: 361\n",
      "  KARACHI:: 195\n",
      "  LONDON:: 160\n",
      "  DUBAI:: 88\n",
      "  SINGAPORE:: 83\n",
      "  DELHI:: 75\n",
      "  LAHORE:: 73\n",
      "  TOKYO:: 72\n",
      "  DHAKA:: 52\n",
      "  YORK:: 51\n",
      "\n",
      "=== RECOMMENDATION ===\n",
      "Based on stats:\n",
      "- Hyphens: HIGH FREQUENCY. Recommendation: Keep hyphenated words intact (e.g., 'supply-side' -> 'supply-side'). Splitting them might lose specific meaning.\n",
      "- Acronyms: DETECTED. Recommendation: Normalize by removing dots (U.S. -> US) to match user queries like 'US'.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Press Enter to continue to Indexing based on these insights... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[System Log]: Building Inverted Index...\n",
      "[System Log]: Indexing complete. Vocabulary size: 43883 terms.\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Query (or 'exit' to quit):  kse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Boolean Retrieval] for 'kse':\n",
      " - Found in Doc ID 97: stock market regains 1100 points to recover from p...\n",
      " - Found in Doc ID 805: Pakistan top emerging economy among South Asian ma...\n",
      " - Found in Doc ID 6: bullish kse jumps over 33000 psychological barrier...\n",
      " - Found in Doc ID 143: kse 100 index sees sharp decline of over 1000 poi...\n",
      " - Found in Doc ID 274: kse 100 plummets over 1000 points in intra day tra...\n",
      " - Found in Doc ID 84: stocks tumble as kse 100 share index drops 817 poi...\n",
      " - Found in Doc ID 251: dollar reaches 17 month high against ru...\n",
      " - Found in Doc ID 253: kse down 1419 points at closing...\n",
      " - Found in Doc ID 94: free fall continues as kse 100 plummets 1000 poi...\n",
      "\n",
      "[Ranked Retrieval - BM25] for 'kse':\n",
      " 1. Doc 253 (Score: 11.2516) | kse down 1419 points at closing\n",
      " 2. Doc 274 (Score: 10.9453) | kse 100 plummets over 1000 points in intra day trading\n",
      " 3. Doc 84 (Score: 10.7883) | stocks tumble as kse 100 share index drops 817 poi\n",
      " 4. Doc 143 (Score: 10.2369) | kse 100 index sees sharp decline of over 1000 poi\n",
      " 5. Doc 6 (Score: 9.7906) | bullish kse jumps over 33000 psychological barrier\n",
      "\n",
      "[Relevance Feedback] Assuming you liked Doc 253...\n",
      " - Optimized Query: 'kse market stock point'\n",
      " - Re-running search with optimized query...\n",
      " 1. Doc 253 (Score: 22.4953) | kse down 1419 points at closing\n",
      " 2. Doc 84 (Score: 21.9765) | stocks tumble as kse 100 share index drops 817 poi\n",
      " 3. Doc 274 (Score: 21.5385) | kse 100 plummets over 1000 points in intra day trading\n",
      " 4. Doc 6 (Score: 20.9599) | bullish kse jumps over 33000 psychological barrier\n",
      " 5. Doc 143 (Score: 18.7256) | kse 100 index sees sharp decline of over 1000 poi\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Query (or 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5d05c7-663e-4df5-af17-98a253ba319f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7ad2b5c-0e5b-4a45-82cb-a53bd704d2f6",
   "metadata": {},
   "source": [
    "# Iteration 2 Lemmatizer and Corpus Analyzer based Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbd1fb8e-8d48-4407-8ee3-65ad15617370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download the necessary lexical database (Run once)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True) # Open Multilingual Wordnet (needed for newer NLTK)\n",
    "\n",
    "class IRConfig:\n",
    "    DATA_PATH = r\"C:\\Users\\user\\Documents\\Sem 3\\HW3\\dataset\\Articles.csv\"\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "    # CHANGE: Swapping Stemmer for Lemmatizer\n",
    "    LEMMATIZER = WordNetLemmatizer() \n",
    "    \n",
    "    # BM25 Hyperparameters\n",
    "    K1 = 1.5\n",
    "    B = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117f3ce6-b09d-429b-8bf5-b63a2c183571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_preprocess(text):\n",
    "    \"\"\"\n",
    "    Expert Tokenizer: \n",
    "    - Keeps Hyphens (left-arm)\n",
    "    - Preserves Uppercase Acronyms (US, KTI)\n",
    "    - Uses Lemmatization instead of Stemming for cleaner vocabulary.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "\n",
    "    # 1. Handle Colons & Headers\n",
    "    text = text.replace(':', ' ')\n",
    "\n",
    "    # 2. Handle Acronyms (U.S. -> US)\n",
    "    text = re.sub(r'\\b(?:[A-Z]\\.)+[A-Z]?\\b', lambda m: m.group(0).replace('.', ''), text)\n",
    "\n",
    "    # 3. Handle Possessives\n",
    "    text = re.sub(r\"\\'s\\b\", \"\", text) \n",
    "    text = text.replace(\"'\", \"\")      \n",
    "\n",
    "    # 4. Tokenize (Split by whitespace)\n",
    "    raw_tokens = text.split()\n",
    "\n",
    "    # 5. Processing Loop\n",
    "    custom_stops = {'said', 'reported', 'added', 'sources', 'also'} \n",
    "    clean_tokens = []\n",
    "\n",
    "    for t in raw_tokens:\n",
    "        # A. Clean non-alphanumeric (BUT keep hyphens)\n",
    "        t_clean = re.sub(r'[^a-zA-Z0-9\\-]', '', t)\n",
    "        \n",
    "        if not t_clean: \n",
    "            continue\n",
    "            \n",
    "        # B. Check for Acronym (All Caps & length > 1)\n",
    "        is_acronym = t_clean.isupper() and len(t_clean) > 1\n",
    "        \n",
    "        # C. Case Normalization logic\n",
    "        if is_acronym:\n",
    "            token_to_process = t_clean # Keep \"US\"\n",
    "        else:\n",
    "            token_to_process = t_clean.lower() # \"Karachi\" -> \"karachi\"\n",
    "\n",
    "        # D. Stopword Check\n",
    "        # Convert to lower just for the check (so \"The\" matches \"the\")\n",
    "        if token_to_process.lower() not in IRConfig.STOPWORDS and token_to_process.lower() not in custom_stops:\n",
    "            \n",
    "            # E. Lemmatization (The Big Change)\n",
    "            if is_acronym:\n",
    "                # Don't touch acronyms. \n",
    "                # WordNet might try to lemmatize 'US' -> 'u' if we aren't careful.\n",
    "                clean_tokens.append(token_to_process)\n",
    "            else:\n",
    "                # Lemmatize normally. \n",
    "                # Note: Default lemmatize() assumes Noun. \n",
    "                # For an extra boost, we try Verb if it ends in 'ing' or 'ed'\n",
    "                lemma = token_to_process\n",
    "                if token_to_process.endswith('ing') or token_to_process.endswith('ed'):\n",
    "                     lemma = IRConfig.LEMMATIZER.lemmatize(token_to_process, pos='v')\n",
    "                else:\n",
    "                     lemma = IRConfig.LEMMATIZER.lemmatize(token_to_process, pos='n')\n",
    "                \n",
    "                clean_tokens.append(lemma)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7e38f5c-8c72-45cf-ad05-1a8056023cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Indexer:\n",
    "    def __init__(self):\n",
    "        self.inverted_index = defaultdict(dict) # term -> {doc_id: freq}\n",
    "        self.doc_lengths = {} # doc_id -> length (needed for BM25)\n",
    "        self.avg_doc_length = 0\n",
    "        self.total_docs = 0\n",
    "        self.corpus_stats = {} # store idf later\n",
    "        \n",
    "    def build_index(self, documents):\n",
    "        \"\"\"\n",
    "        Constructs the inverted index from the document corpus.\n",
    "        \"\"\"\n",
    "        log(\"Building Inverted Index...\")\n",
    "        total_length = 0\n",
    "        \n",
    "        for doc in documents:\n",
    "            doc_id = doc['id']\n",
    "            # We index both Heading and Article Content for better recall\n",
    "            full_text = f\"{doc['heading']} {doc['content']}\"\n",
    "            tokens = advanced_preprocess(full_text)\n",
    "            \n",
    "            # 1. Update Document Lengths (for BM25 normalization)\n",
    "            self.doc_lengths[doc_id] = len(tokens)\n",
    "            total_length += len(tokens)\n",
    "            \n",
    "            # 2. Build Inverted Index\n",
    "            term_freqs = Counter(tokens)\n",
    "            for term, freq in term_freqs.items():\n",
    "                self.inverted_index[term][doc_id] = freq\n",
    "                \n",
    "        self.total_docs = len(documents)\n",
    "        self.avg_doc_length = total_length / self.total_docs if self.total_docs > 0 else 0\n",
    "        \n",
    "        log(f\"Indexing complete. Vocabulary size: {len(self.inverted_index)} terms.\")\n",
    "        \n",
    "    def get_postings(self, term):\n",
    "        \"\"\"Returns {doc_id: freq} for a given term.\"\"\"\n",
    "        return self.inverted_index.get(term, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e075dcd-6379-43a6-ab09-b5761a39e911",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalSystem2:\n",
    "    def __init__(self, indexer):\n",
    "        self.indexer = indexer\n",
    "        \n",
    "    def _calculate_idf(self, term):\n",
    "        \"\"\"\n",
    "        Calculates Inverse Document Frequency (IDF) for a term.\n",
    "        Using standard log formulation.\n",
    "        \"\"\"\n",
    "        doc_freq = len(self.indexer.get_postings(term))\n",
    "        if doc_freq == 0:\n",
    "            return 0\n",
    "        # Standard IDF formula: log( (N - n + 0.5) / (n + 0.5) + 1 ) \n",
    "        # Adding 1 to avoid negative values\n",
    "        N = self.indexer.total_docs\n",
    "        return math.log(1 + (N - doc_freq + 0.5) / (doc_freq + 0.5))\n",
    "\n",
    "    def boolean_retrieve(self, query):\n",
    "        \"\"\"\n",
    "        Basic AND retrieval. Returns documents containing ALL query terms.\n",
    "        \"\"\"\n",
    "        query_terms = advanced_preprocess(query)\n",
    "        if not query_terms:\n",
    "            return []\n",
    "        \n",
    "        # Start with the set of docs for the first term\n",
    "        first_term_docs = set(self.indexer.get_postings(query_terms[0]).keys())\n",
    "        \n",
    "        # Intersect with all other terms\n",
    "        for term in query_terms[1:]:\n",
    "            term_docs = set(self.indexer.get_postings(term).keys())\n",
    "            first_term_docs = first_term_docs.intersection(term_docs)\n",
    "            \n",
    "        return list(first_term_docs)\n",
    "\n",
    "    def bm25_rank(self, query, top_k=5):\n",
    "        \"\"\"\n",
    "        Performs Ranked Retrieval using Okapi BM25.\n",
    "        \"\"\"\n",
    "        query_terms = advanced_preprocess(query)\n",
    "        scores = defaultdict(float)\n",
    "        \n",
    "        for term in query_terms:\n",
    "            postings = self.indexer.get_postings(term)\n",
    "            idf = self._calculate_idf(term)\n",
    "            \n",
    "            for doc_id, freq in postings.items():\n",
    "                # BM25 Component Calculation\n",
    "                doc_len = self.indexer.doc_lengths[doc_id]\n",
    "                avg_len = self.indexer.avg_doc_length\n",
    "                k1 = IRConfig.K1\n",
    "                b = IRConfig.B\n",
    "                \n",
    "                numerator = freq * (k1 + 1)\n",
    "                denominator = freq + k1 * (1 - b + b * (doc_len / avg_len))\n",
    "                \n",
    "                # Accumulate score for this doc\n",
    "                scores[doc_id] += idf * (numerator / denominator)\n",
    "                \n",
    "        # Sort by score descending\n",
    "        ranked_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        return ranked_docs[:top_k]\n",
    "\n",
    "    def expand_query_with_feedback(self, original_query, relevant_doc_id, alpha=1.0, beta=0.75):\n",
    "            \"\"\"\n",
    "            Simple Rocchio-like Feedback:\n",
    "            New Query Vector = Alpha * Old Query + Beta * Relevant Doc Vector\n",
    "            \n",
    "            In practice (for text), we append top terms from the relevant doc to the query.\n",
    "            \"\"\"\n",
    "            # Get terms from the relevant document\n",
    "            relevant_doc_terms = []\n",
    "            for term, postings in self.indexer.inverted_index.items():\n",
    "                if relevant_doc_id in postings:\n",
    "                    relevant_doc_terms.append(term)\n",
    "            \n",
    "            # Simple implementation: Add top 3 most frequent terms from the doc \n",
    "            # that aren't already in the query\n",
    "            current_terms = set(advanced_preprocess(original_query))\n",
    "            \n",
    "            # Sort doc terms by frequency in that doc\n",
    "            sorted_terms = sorted(relevant_doc_terms, \n",
    "                                  key=lambda t: self.indexer.inverted_index[t][relevant_doc_id], \n",
    "                                  reverse=True)\n",
    "            \n",
    "            added = 0\n",
    "            new_query_parts = [original_query]\n",
    "            \n",
    "            for term in sorted_terms:\n",
    "                if term not in current_terms and added < 3:\n",
    "                    new_query_parts.append(term)\n",
    "                    added += 1\n",
    "                    \n",
    "            return \" \".join(new_query_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ec6a833-b015-4946-a4f7-5a34c958a83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN EXECUTION PIPELINE\n",
    "\n",
    "def main():\n",
    "    # 1. Initialize System\n",
    "    log(\"Initializing CS516 IR System...\")\n",
    "    \n",
    "    # NOTE: You would use the path provided in your prompt:\n",
    "    filepath = r\"C:\\Users\\user\\Documents\\Sem 3\\HW3\\dataset\\Articles.csv\"\n",
    "    \n",
    "    # For demonstration purposes, I will create a dummy CSV file to make this code runnable right now\n",
    "    # In your local jupyter, you can skip this 'create_dummy_csv' step.\n",
    "    # create_dummy_csv(filepath) \n",
    "    \n",
    "    docs = load_data(filepath)\n",
    "    if not docs:\n",
    "        return\n",
    "\n",
    "    # ... after loading docs ...\n",
    "    analyzer = CorpusAnalyzer(docs)\n",
    "    analyzer.analyze()\n",
    "    analyzer.print_report()\n",
    "    \n",
    "    # Pause to let you read the report\n",
    "    input(\"\\nPress Enter to continue to Indexing based on these insights...\")\n",
    "    \n",
    "    # 2. Build Index\n",
    "    indexer = Indexer()\n",
    "    indexer.build_index(docs)\n",
    "    \n",
    "    # 3. Init Retrieval Engine\n",
    "    engine = RetrievalSystem2(indexer)\n",
    "    \n",
    "    # 4. Interactive Loop\n",
    "    while True:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        user_query = input(\"Enter Query (or 'exit' to quit): \")\n",
    "        if user_query.lower() == 'exit':\n",
    "            break\n",
    "            \n",
    "        # Boolean Search\n",
    "        print(f\"\\n[Boolean Retrieval] for '{user_query}':\")\n",
    "        bool_results = engine.boolean_retrieve(user_query)\n",
    "        if bool_results:\n",
    "            for doc_id in bool_results:\n",
    "                print(f\" - Found in Doc ID {doc_id}: {docs[doc_id]['heading'][:50]}...\")\n",
    "        else:\n",
    "            print(\" - No exact matches found (Boolean).\")\n",
    "\n",
    "        # Ranked Retrieval (BM25)\n",
    "        print(f\"\\n[Ranked Retrieval - BM25] for '{user_query}':\")\n",
    "        ranked_results = engine.bm25_rank(user_query)\n",
    "        \n",
    "        if not ranked_results:\n",
    "            print(\" - No relevant documents found.\")\n",
    "            continue\n",
    "            \n",
    "        for rank, (doc_id, score) in enumerate(ranked_results, 1):\n",
    "            print(f\" {rank}. Doc {doc_id} (Score: {score:.4f}) | {docs[doc_id]['heading']}\")\n",
    "            \n",
    "        # Relevance Feedback\n",
    "        # Let's assume the user liked the first result and wants \"more like this\"\n",
    "        if ranked_results:\n",
    "            top_doc_id = ranked_results[0][0]\n",
    "            print(f\"\\n[Relevance Feedback] Assuming you liked Doc {top_doc_id}...\")\n",
    "            expanded_query = engine.expand_query_with_feedback(user_query, top_doc_id)\n",
    "            print(f\" - Optimized Query: '{expanded_query}'\")\n",
    "            print(\" - Re-running search with optimized query...\")\n",
    "            \n",
    "            new_results = engine.bm25_rank(expanded_query)\n",
    "            for rank, (doc_id, score) in enumerate(new_results, 1):\n",
    "                print(f\" {rank}. Doc {doc_id} (Score: {score:.4f}) | {docs[doc_id]['heading']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c693c4e-dbd0-44a6-bc18-48fb72b160b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[System Log]: Initializing CS516 IR System...\n",
      "[System Log]: Loading dataset from C:\\Users\\user\\Documents\\Sem 3\\HW3\\dataset\\Articles.csv...\n",
      "[System Log]: Attempting to load with encoding: utf-8...\n",
      "[System Log]: Failed with encoding: utf-8, trying next...\n",
      "[System Log]: Attempting to load with encoding: cp1252...\n",
      "[System Log]: Success with encoding: cp1252\n",
      "[System Log]: Successfully loaded 2692 documents.\n",
      "Analyzing corpus for special token patterns...\n",
      "\n",
      "=== CORPUS ANALYSIS REPORT ===\n",
      "\n",
      "[Hyphenated Words] Top 10 of 2855 unique:\n",
      "  year-old: 416\n",
      "  one-day: 170\n",
      "  left-arm: 157\n",
      "  all-rounder: 104\n",
      "  semi-final: 92\n",
      "  Misbah-ul: 91\n",
      "  leg-spinner: 86\n",
      "  semi-finals: 83\n",
      "  Asia-Pacific: 76\n",
      "  five-year: 73\n",
      "\n",
      "[Apostrophes] Top 10 of 784 unique:\n",
      "  world's: 152\n",
      "  It's: 131\n",
      "  Pakistan's: 117\n",
      "  country's: 95\n",
      "  China's: 91\n",
      "  India's: 90\n",
      "  it's: 88\n",
      "  I'm: 79\n",
      "  England's: 73\n",
      "  don't: 70\n",
      "\n",
      "[Acronyms] Top 10 of 28 unique:\n",
      "  U.S: 746\n",
      "  D.: 5\n",
      "  U.K: 5\n",
      "  U.S.: 4\n",
      "  D.G: 2\n",
      "  D.C: 2\n",
      "  U.N: 2\n",
      "  C.: 2\n",
      "  J.P: 2\n",
      "  A.B: 2\n",
      "\n",
      "[Colons/Headers] Top 10:\n",
      "  ISLAMABAD:: 361\n",
      "  KARACHI:: 195\n",
      "  LONDON:: 160\n",
      "  DUBAI:: 88\n",
      "  SINGAPORE:: 83\n",
      "  DELHI:: 75\n",
      "  LAHORE:: 73\n",
      "  TOKYO:: 72\n",
      "  DHAKA:: 52\n",
      "  YORK:: 51\n",
      "\n",
      "=== RECOMMENDATION ===\n",
      "Based on stats:\n",
      "- Hyphens: HIGH FREQUENCY. Recommendation: Keep hyphenated words intact (e.g., 'supply-side' -> 'supply-side'). Splitting them might lose specific meaning.\n",
      "- Acronyms: DETECTED. Recommendation: Normalize by removing dots (U.S. -> US) to match user queries like 'US'.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Press Enter to continue to Indexing based on these insights... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[System Log]: Building Inverted Index...\n",
      "[System Log]: Indexing complete. Vocabulary size: 47519 terms.\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Query (or 'exit' to quit):  kse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Boolean Retrieval] for 'kse':\n",
      " - Found in Doc ID 6: bullish kse jumps over 33000 psychological barrier...\n",
      " - Found in Doc ID 143: kse 100 index sees sharp decline of over 1000 poi...\n",
      " - Found in Doc ID 274: kse 100 plummets over 1000 points in intra day tra...\n",
      " - Found in Doc ID 84: stocks tumble as kse 100 share index drops 817 poi...\n",
      " - Found in Doc ID 253: kse down 1419 points at closing...\n",
      " - Found in Doc ID 94: free fall continues as kse 100 plummets 1000 poi...\n",
      "\n",
      "[Ranked Retrieval - BM25] for 'kse':\n",
      " 1. Doc 143 (Score: 8.5737) | kse 100 index sees sharp decline of over 1000 poi\n",
      " 2. Doc 253 (Score: 8.5442) | kse down 1419 points at closing\n",
      " 3. Doc 6 (Score: 7.9940) | bullish kse jumps over 33000 psychological barrier\n",
      " 4. Doc 84 (Score: 7.7933) | stocks tumble as kse 100 share index drops 817 poi\n",
      " 5. Doc 94 (Score: 7.7689) | free fall continues as kse 100 plummets 1000 poi\n",
      "\n",
      "[Relevance Feedback] Assuming you liked Doc 143...\n",
      " - Optimized Query: 'kse market share company'\n",
      " - Re-running search with optimized query...\n",
      " 1. Doc 143 (Score: 18.7947) | kse 100 index sees sharp decline of over 1000 poi\n",
      " 2. Doc 253 (Score: 14.6342) | kse down 1419 points at closing\n",
      " 3. Doc 84 (Score: 14.2804) | stocks tumble as kse 100 share index drops 817 poi\n",
      " 4. Doc 6 (Score: 11.0156) | bullish kse jumps over 33000 psychological barrier\n",
      " 5. Doc 94 (Score: 10.2796) | free fall continues as kse 100 plummets 1000 poi\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Query (or 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79a877c-720d-4128-b28f-82a6d2341fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58af8743-8a32-44d7-99a3-11e84d1fe6c0",
   "metadata": {},
   "source": [
    "#Iteration-3 Domain specific stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20f237e0-ece5-4ef1-8ab7-069e01ec9913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[System Log]: Loading dataset from C:\\Users\\user\\Documents\\Sem 3\\HW3\\dataset\\Articles.csv...\n",
      "[System Log]: Attempting to load with encoding: utf-8...\n",
      "[System Log]: Failed with encoding: utf-8, trying next...\n",
      "[System Log]: Attempting to load with encoding: cp1252...\n",
      "[System Log]: Success with encoding: cp1252\n",
      "[System Log]: Successfully loaded 2692 documents.\n",
      "\n",
      "[Analysis]: Scanning corpus for top 50 frequent terms...\n",
      "\n",
      "--- TOP 50 MOST FREQUENT TERMS (Candidates for Custom Stopwords) ---\n",
      "Term                 | Frequency  |  Recommendation\n",
      "--------------------------------------------------\n",
      "said                 | 5057       | [ALREADY CAUGHT]\n",
      "percent              | 3033       | [ALREADY CAUGHT]\n",
      "pakistan             | 2697       | -> CONSIDER ADDING\n",
      "first                | 2278       | -> CONSIDER ADDING\n",
      "us                   | 2033       | -> CONSIDER ADDING\n",
      "oil                  | 2020       | -> CONSIDER ADDING\n",
      "also                 | 1914       | [ALREADY CAUGHT]\n",
      "last                 | 1886       | -> CONSIDER ADDING\n",
      "world                | 1737       | -> CONSIDER ADDING\n",
      "new                  | 1718       | [ALREADY CAUGHT]\n",
      "two                  | 1714       | [ALREADY CAUGHT]\n",
      "year                 | 1555       | [ALREADY CAUGHT]\n",
      "would                | 1550       | -> CONSIDER ADDING\n",
      "one                  | 1393       | -> CONSIDER ADDING\n",
      "prices               | 1359       | -> CONSIDER ADDING\n",
      "cricket              | 1348       | -> CONSIDER ADDING\n",
      "million              | 1337       | -> CONSIDER ADDING\n",
      "test                 | 1335       | -> CONSIDER ADDING\n",
      "england              | 1303       | -> CONSIDER ADDING\n",
      "three                | 1195       | -> CONSIDER ADDING\n",
      "team                 | 1134       | -> CONSIDER ADDING\n",
      "second               | 1093       | -> CONSIDER ADDING\n",
      "billion              | 1061       | -> CONSIDER ADDING\n",
      "market               | 1052       | -> CONSIDER ADDING\n",
      "india                | 1028       | -> CONSIDER ADDING\n",
      "match                | 1027       | -> CONSIDER ADDING\n",
      "international        | 1014       | -> CONSIDER ADDING\n",
      "since                | 987        | -> CONSIDER ADDING\n",
      "crude                | 977        | -> CONSIDER ADDING\n",
      "could                | 966        | -> CONSIDER ADDING\n",
      "made                 | 963        | -> CONSIDER ADDING\n",
      "time                 | 919        | -> CONSIDER ADDING\n",
      "captain              | 899        | -> CONSIDER ADDING\n",
      "day                  | 874        | -> CONSIDER ADDING\n",
      "global               | 862        | -> CONSIDER ADDING\n",
      "years                | 853        | -> CONSIDER ADDING\n",
      "minister             | 842        | -> CONSIDER ADDING\n",
      "bank                 | 834        | -> CONSIDER ADDING\n",
      "four                 | 813        | -> CONSIDER ADDING\n",
      "government           | 811        | -> CONSIDER ADDING\n",
      "week                 | 792        | -> CONSIDER ADDING\n",
      "runs                 | 775        | -> CONSIDER ADDING\n",
      "win                  | 742        | -> CONSIDER ADDING\n",
      "back                 | 731        | -> CONSIDER ADDING\n",
      "south                | 715        | -> CONSIDER ADDING\n",
      "per                  | 707        | -> CONSIDER ADDING\n",
      "told                 | 706        | -> CONSIDER ADDING\n",
      "economic             | 701        | -> CONSIDER ADDING\n",
      "series               | 700        | -> CONSIDER ADDING\n",
      "markets              | 678        | -> CONSIDER ADDING\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "filepath = r\"C:\\Users\\user\\Documents\\Sem 3\\HW3\\dataset\\Articles.csv\"\n",
    "docs = load_data(filepath)\n",
    "\n",
    "class CorpusAnalyzer2:\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "        self.stats = {\n",
    "            \"hyphens\": Counter(),\n",
    "            \"apostrophes\": Counter(),\n",
    "            \"acronyms\": Counter(),\n",
    "            \"colons\": Counter(),\n",
    "            \"numbers\": Counter()\n",
    "        }\n",
    "\n",
    "    def analyze(self):\n",
    "        print(\"Analyzing corpus for special token patterns...\")\n",
    "        \n",
    "        for doc in self.documents:\n",
    "            text = f\"{doc['heading']} {doc['content']}\"\n",
    "            \n",
    "            # 1. Hyphenated words (e.g., \"supply-side\", \"co-operation\")\n",
    "            # Matches word-word but excludes simple minuses between numbers\n",
    "            hyphens = re.findall(r'\\b[a-zA-Z]+-[a-zA-Z]+\\b', text)\n",
    "            self.stats[\"hyphens\"].update(hyphens)\n",
    "            \n",
    "            # 2. Apostrophes (Possessives vs Contractions)\n",
    "            # Matches word's or word't, etc.\n",
    "            apostrophes = re.findall(r'\\b[a-zA-Z]+\\'[a-zA-Z]+\\b', text)\n",
    "            self.stats[\"apostrophes\"].update(apostrophes)\n",
    "            \n",
    "            # 3. Acronyms / Abbreviations with dots (e.g., U.S., U.N., K.T.I.)\n",
    "            # Matches capital letter followed by dot, repeated\n",
    "            acronyms = re.findall(r'\\b(?:[A-Z]\\.)+[A-Z]?\\b', text)\n",
    "            self.stats[\"acronyms\"].update(acronyms)\n",
    "            \n",
    "            # 4. Colons (often used in news for \"KARACHI: ...\")\n",
    "            # Matches Word: at the start of lines or sentences\n",
    "            colons = re.findall(r'\\b[A-Z][a-zA-Z]*:', text)\n",
    "            self.stats[\"colons\"].update(colons)\n",
    "\n",
    "    def print_report(self):\n",
    "        print(\"\\n=== CORPUS ANALYSIS REPORT ===\")\n",
    "        \n",
    "        print(f\"\\n[Hyphenated Words] Top 10 of {len(self.stats['hyphens'])} unique:\")\n",
    "        for w, c in self.stats['hyphens'].most_common(10):\n",
    "            print(f\"  {w}: {c}\")\n",
    "            \n",
    "        print(f\"\\n[Apostrophes] Top 10 of {len(self.stats['apostrophes'])} unique:\")\n",
    "        for w, c in self.stats['apostrophes'].most_common(10):\n",
    "            print(f\"  {w}: {c}\")\n",
    "            \n",
    "        print(f\"\\n[Acronyms] Top 10 of {len(self.stats['acronyms'])} unique:\")\n",
    "        for w, c in self.stats['acronyms'].most_common(10):\n",
    "            print(f\"  {w}: {c}\")\n",
    "            \n",
    "        print(f\"\\n[Colons/Headers] Top 10:\")\n",
    "        for w, c in self.stats['colons'].most_common(10):\n",
    "            print(f\"  {w}: {c}\")\n",
    "\n",
    "        print(\"\\n=== RECOMMENDATION ===\")\n",
    "        self._generate_recommendation()\n",
    "\n",
    "    def _generate_recommendation(self):\n",
    "        # Heuristics for auto-recommendation\n",
    "        hyphen_count = sum(self.stats['hyphens'].values())\n",
    "        acronym_count = sum(self.stats['acronyms'].values())\n",
    "        \n",
    "        print(\"Based on stats:\")\n",
    "        if hyphen_count > 100:\n",
    "            print(\"- Hyphens: HIGH FREQUENCY. Recommendation: Keep hyphenated words intact (e.g., 'supply-side' -> 'supply-side'). Splitting them might lose specific meaning.\")\n",
    "        else:\n",
    "            print(\"- Hyphens: Low frequency. Recommendation: Split freely.\")\n",
    "\n",
    "        if acronym_count > 50:\n",
    "            print(\"- Acronyms: DETECTED. Recommendation: Normalize by removing dots (U.S. -> US) to match user queries like 'US'.\")\n",
    "\n",
    "    def analyze_top_frequent_terms(documents, top_n=50):\n",
    "        \"\"\"\n",
    "        Scans the corpus to find the most frequent terms.\n",
    "        Helps in identifying domain-specific stopwords.\n",
    "        \"\"\"\n",
    "        print(f\"\\n[Analysis]: Scanning corpus for top {top_n} frequent terms...\")\n",
    "        \n",
    "        # We use a Counter to track term frequency across the entire collection\n",
    "        corpus_freq = Counter()\n",
    "        \n",
    "        # We want to check frequencies AFTER standard stopwords are removed \n",
    "        # but BEFORE your custom list is applied, to see what 'leaks' through.\n",
    "        \n",
    "        # Temporary set of standard NLTK stopwords for filtering\n",
    "        standard_stops = IRConfig.STOPWORDS \n",
    "        \n",
    "        for doc in documents:\n",
    "            # Use a simplified tokenizer here to just get raw words\n",
    "            # We simulate the process: Lowercase -> Split -> Remove Standard Stops\n",
    "            text = f\"{doc['heading']} {doc['content']}\".lower()\n",
    "            # Remove simple punctuation for accurate counting\n",
    "            text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "            tokens = text.split()\n",
    "            \n",
    "            # Filter only standard English stopwords to see what remains\n",
    "            filtered = [t for t in tokens if t not in standard_stops]\n",
    "            corpus_freq.update(filtered)\n",
    "            \n",
    "        print(f\"\\n--- TOP {top_n} MOST FREQUENT TERMS (Candidates for Custom Stopwords) ---\")\n",
    "        print(f\"{'Term':<20} | {'Frequency':<10} | {' Recommendation'}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for term, freq in corpus_freq.most_common(top_n):\n",
    "            # Heuristic: If it looks like a reporting verb or generic noun, we flag it\n",
    "            recommendation = \"\"\n",
    "            common_news_stops = {'said', 'reported', 'added', 'also', 'sources', 'share', 'percent', 'year', 'new', 'two'}\n",
    "            \n",
    "            if term in common_news_stops:\n",
    "                recommendation = \"[ALREADY CAUGHT]\"\n",
    "            elif freq > len(documents) * 0.1: # If term appears in >10% of docs (rough heuristic)\n",
    "                recommendation = \"-> CONSIDER ADDING\"\n",
    "                \n",
    "            print(f\"{term:<20} | {freq:<10} | {recommendation}\")\n",
    "    \n",
    "    # --- RUN THIS INTERACTIVELY ---\n",
    "    analyze_top_frequent_terms(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe0dc9e9-bef1-4d93-9eb6-267173b37bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MAIN EXECUTION PIPELINE ---\n",
    "\n",
    "def main():\n",
    "    # 1. Initialize System\n",
    "    log(\"Initializing CS516 IR System...\")\n",
    "    \n",
    "    # NOTE: You would use the path provided in your prompt:\n",
    "    filepath = r\"C:\\Users\\user\\Documents\\Sem 3\\HW3\\dataset\\Articles.csv\"\n",
    "    \n",
    "    # For demonstration purposes, I will create a dummy CSV file to make this code runnable right now\n",
    "    # In your local jupyter, you can skip this 'create_dummy_csv' step.\n",
    "    # create_dummy_csv(filepath) \n",
    "    \n",
    "    docs = load_data(filepath)\n",
    "    if not docs:\n",
    "        return\n",
    "\n",
    "    # ... after loading docs ...\n",
    "    analyzer = CorpusAnalyzer2(docs)\n",
    "    analyzer.analyze()\n",
    "    analyzer.print_report()\n",
    "    \n",
    "    # Pause to let you read the report\n",
    "    input(\"\\nPress Enter to continue to Indexing based on these insights...\")\n",
    "    \n",
    "    # 2. Build Index\n",
    "    indexer = Indexer()\n",
    "    indexer.build_index(docs)\n",
    "    \n",
    "    # 3. Init Retrieval Engine\n",
    "    engine = RetrievalSystem2(indexer)\n",
    "    \n",
    "    # 4. Interactive Loop\n",
    "    while True:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        user_query = input(\"Enter Query (or 'exit' to quit): \")\n",
    "        if user_query.lower() == 'exit':\n",
    "            break\n",
    "            \n",
    "        # -- VARIANT A: Boolean Search --\n",
    "        print(f\"\\n[Boolean Retrieval] for '{user_query}':\")\n",
    "        bool_results = engine.boolean_retrieve(user_query)\n",
    "        if bool_results:\n",
    "            for doc_id in bool_results:\n",
    "                print(f\" - Found in Doc ID {doc_id}: {docs[doc_id]['heading'][:50]}...\")\n",
    "        else:\n",
    "            print(\" - No exact matches found (Boolean).\")\n",
    "\n",
    "        # -- VARIANT B: Ranked Retrieval (BM25) --\n",
    "        print(f\"\\n[Ranked Retrieval - BM25] for '{user_query}':\")\n",
    "        ranked_results = engine.bm25_rank(user_query)\n",
    "        \n",
    "        if not ranked_results:\n",
    "            print(\" - No relevant documents found.\")\n",
    "            continue\n",
    "            \n",
    "        for rank, (doc_id, score) in enumerate(ranked_results, 1):\n",
    "            print(f\" {rank}. Doc {doc_id} (Score: {score:.4f}) | {docs[doc_id]['heading']}\")\n",
    "            \n",
    "        # -- VARIANT C: Relevance Feedback Demo --\n",
    "        # Let's assume the user liked the first result and wants \"more like this\"\n",
    "        if ranked_results:\n",
    "            top_doc_id = ranked_results[0][0]\n",
    "            print(f\"\\n[Relevance Feedback] Assuming you liked Doc {top_doc_id}...\")\n",
    "            expanded_query = engine.expand_query_with_feedback(user_query, top_doc_id)\n",
    "            print(f\" - Optimized Query: '{expanded_query}'\")\n",
    "            print(\" - Re-running search with optimized query...\")\n",
    "            \n",
    "            new_results = engine.bm25_rank(expanded_query)\n",
    "            for rank, (doc_id, score) in enumerate(new_results, 1):\n",
    "                print(f\" {rank}. Doc {doc_id} (Score: {score:.4f}) | {docs[doc_id]['heading']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e445c4f-1312-4e75-a38c-9341620fd6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[System Log]: Initializing CS516 IR System...\n",
      "[System Log]: Loading dataset from C:\\Users\\user\\Documents\\Sem 3\\HW3\\dataset\\Articles.csv...\n",
      "[System Log]: Attempting to load with encoding: utf-8...\n",
      "[System Log]: Failed with encoding: utf-8, trying next...\n",
      "[System Log]: Attempting to load with encoding: cp1252...\n",
      "[System Log]: Success with encoding: cp1252\n",
      "[System Log]: Successfully loaded 2692 documents.\n",
      "Analyzing corpus for special token patterns...\n",
      "\n",
      "=== CORPUS ANALYSIS REPORT ===\n",
      "\n",
      "[Hyphenated Words] Top 10 of 2855 unique:\n",
      "  year-old: 416\n",
      "  one-day: 170\n",
      "  left-arm: 157\n",
      "  all-rounder: 104\n",
      "  semi-final: 92\n",
      "  Misbah-ul: 91\n",
      "  leg-spinner: 86\n",
      "  semi-finals: 83\n",
      "  Asia-Pacific: 76\n",
      "  five-year: 73\n",
      "\n",
      "[Apostrophes] Top 10 of 784 unique:\n",
      "  world's: 152\n",
      "  It's: 131\n",
      "  Pakistan's: 117\n",
      "  country's: 95\n",
      "  China's: 91\n",
      "  India's: 90\n",
      "  it's: 88\n",
      "  I'm: 79\n",
      "  England's: 73\n",
      "  don't: 70\n",
      "\n",
      "[Acronyms] Top 10 of 28 unique:\n",
      "  U.S: 746\n",
      "  D.: 5\n",
      "  U.K: 5\n",
      "  U.S.: 4\n",
      "  D.G: 2\n",
      "  D.C: 2\n",
      "  U.N: 2\n",
      "  C.: 2\n",
      "  J.P: 2\n",
      "  A.B: 2\n",
      "\n",
      "[Colons/Headers] Top 10:\n",
      "  ISLAMABAD:: 361\n",
      "  KARACHI:: 195\n",
      "  LONDON:: 160\n",
      "  DUBAI:: 88\n",
      "  SINGAPORE:: 83\n",
      "  DELHI:: 75\n",
      "  LAHORE:: 73\n",
      "  TOKYO:: 72\n",
      "  DHAKA:: 52\n",
      "  YORK:: 51\n",
      "\n",
      "=== RECOMMENDATION ===\n",
      "Based on stats:\n",
      "- Hyphens: HIGH FREQUENCY. Recommendation: Keep hyphenated words intact (e.g., 'supply-side' -> 'supply-side'). Splitting them might lose specific meaning.\n",
      "- Acronyms: DETECTED. Recommendation: Normalize by removing dots (U.S. -> US) to match user queries like 'US'.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Press Enter to continue to Indexing based on these insights... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[System Log]: Building Inverted Index...\n",
      "[System Log]: Indexing complete. Vocabulary size: 47519 terms.\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Query (or 'exit' to quit):  kse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Boolean Retrieval] for 'kse':\n",
      " - Found in Doc ID 6: bullish kse jumps over 33000 psychological barrier...\n",
      " - Found in Doc ID 143: kse 100 index sees sharp decline of over 1000 poi...\n",
      " - Found in Doc ID 274: kse 100 plummets over 1000 points in intra day tra...\n",
      " - Found in Doc ID 84: stocks tumble as kse 100 share index drops 817 poi...\n",
      " - Found in Doc ID 253: kse down 1419 points at closing...\n",
      " - Found in Doc ID 94: free fall continues as kse 100 plummets 1000 poi...\n",
      "\n",
      "[Ranked Retrieval - BM25] for 'kse':\n",
      " 1. Doc 143 (Score: 8.5737) | kse 100 index sees sharp decline of over 1000 poi\n",
      " 2. Doc 253 (Score: 8.5442) | kse down 1419 points at closing\n",
      " 3. Doc 6 (Score: 7.9940) | bullish kse jumps over 33000 psychological barrier\n",
      " 4. Doc 84 (Score: 7.7933) | stocks tumble as kse 100 share index drops 817 poi\n",
      " 5. Doc 94 (Score: 7.7689) | free fall continues as kse 100 plummets 1000 poi\n",
      "\n",
      "[Relevance Feedback] Assuming you liked Doc 143...\n",
      " - Optimized Query: 'kse market share company'\n",
      " - Re-running search with optimized query...\n",
      " 1. Doc 143 (Score: 18.7947) | kse 100 index sees sharp decline of over 1000 poi\n",
      " 2. Doc 253 (Score: 14.6342) | kse down 1419 points at closing\n",
      " 3. Doc 84 (Score: 14.2804) | stocks tumble as kse 100 share index drops 817 poi\n",
      " 4. Doc 6 (Score: 11.0156) | bullish kse jumps over 33000 psychological barrier\n",
      " 5. Doc 94 (Score: 10.2796) | free fall continues as kse 100 plummets 1000 poi\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Query (or 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dede4f7-2f10-42ab-bc5d-5fdfdeef93c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 50\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m recall_score\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# --- HOW TO RUN IT ---\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Add this inside your main() loop or run separately:\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m SimpleEvaluator(engine, docs)\n\u001b[0;32m     51\u001b[0m score \u001b[38;5;241m=\u001b[39m evaluator\u001b[38;5;241m.\u001b[39mrun_known_item_test()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'engine' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class SimpleEvaluator:\n",
    "    def __init__(self, retrieval_system, documents):\n",
    "        self.system = retrieval_system\n",
    "        self.documents = documents\n",
    "\n",
    "    def run_known_item_test(self, num_queries=20, top_k=5):\n",
    "        \"\"\"\n",
    "        Picks 'num_queries' random documents.\n",
    "        Uses their 'heading' as the query.\n",
    "        Checks if the correct document ID appears in the top 'top_k' results.\n",
    "        Returns: Recall@K Score (0.0 to 1.0)\n",
    "        \"\"\"\n",
    "        print(f\"\\n--- RUNNING KNOWN-ITEM EVALUATION (n={num_queries}, k={top_k}) ---\")\n",
    "        \n",
    "        hits = 0\n",
    "        \n",
    "        # Select random documents to test\n",
    "        test_docs = random.sample(self.documents, min(num_queries, len(self.documents)))\n",
    "        \n",
    "        for i, doc in enumerate(test_docs):\n",
    "            target_id = doc['id']\n",
    "            query = doc['heading']\n",
    "            \n",
    "            # Run the search\n",
    "            results = self.system.bm25_rank(query, top_k=top_k)\n",
    "            retrieved_ids = [r[0] for r in results]\n",
    "            \n",
    "            # Check if our target document is in the retrieved list\n",
    "            if target_id in retrieved_ids:\n",
    "                hits += 1\n",
    "                status = \"HIT\"\n",
    "            else:\n",
    "                status = \"MISS\"\n",
    "                \n",
    "            # Print first 5 for sanity check (optional)\n",
    "            if i < 5: \n",
    "                print(f\"Query: '{query[:30]}...' -> {status}\")\n",
    "\n",
    "        recall_score = hits / num_queries\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Success Rate (Recall@{top_k}): {recall_score:.2%} ({hits}/{num_queries})\")\n",
    "        print(\"-\" * 40)\n",
    "        return recall_score\n",
    "\n",
    "# --- HOW TO RUN IT ---\n",
    "# Add this inside your main() loop or run separately:\n",
    "\n",
    "evaluator = SimpleEvaluator(engine, docs)\n",
    "score = evaluator.run_known_item_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4e7f64-aeff-46fe-bb9d-1ced0ef9d749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpatialDS",
   "language": "python",
   "name": "spatialds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
